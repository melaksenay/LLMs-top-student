 || 
 || 
Hey. Could you turn this down for a sec? || Could you turn this down for a sec?
 || 
So, this is the the motivation we're going to talk about, and || 
In the remainder of this lecture, I'll take you through the structure of the course, and then describe, a little bit more some of the motivations for why I should study a deep reinforcement. || In the remainder of this lecture, I'll take you through the structure of the course, and then describe, a little bit more some of the motivations for why I should study a deep reinforcement.
Let's talk about what we'll cover in the class. So this course goes through. || So this course goes through.
A variety of deep reinforcement methods. It's true very broadly, but we'll start with some basics. Let's start by talking about how we can take a journey for supervised learning. || Let's start by talking about how we can take a journey for supervised learning.
Methods do decision making methods, provide some definitions, and generally, you come to understand the reinforcement problem. Then we have a unit of model for your reinforcement problems. || Then we have a unit of model for your reinforcement problems.
We will cover cumulative policy gradient and actual credit methods, and we'll have some homework script with the UNIX. And then we'll have another unit on model based algorithms. We'll talk about planning on to control. || We'll talk about planning on to control.
Sequence models, images, and things like that. And then we have a variety of more advanced topics. We're going to cover exploration algorithms. We're going to cover algorithms for offline reinforcement. || We're going to cover exploration algorithms. We're going to cover algorithms for offline reinforcement.
 || 
 || 
 || 
 || 
 || 
 || 
 || 
 || 
 || 
